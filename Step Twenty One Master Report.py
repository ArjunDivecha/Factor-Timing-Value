"""
Step Twenty One Master Report

INPUT FILES (discovered at runtime):
- Root folder: Current script directory (where this script is located)
- All '*.pdf' files found recursively under the root (unless excluded via CLI options)
  - Intended sources: PDF outputs produced by prior step scripts (e.g., 'Step Zero ...', 'Step One ...', ..., 'Step Twenty ...')
  - Deterministic ordering: by semantic Step that produced each PDF (parsed from step script filename),
    including 'Point' minors (e.g., 'Two Point Five'), then filename, then full path

OUTPUT FILES (written to root by default):
- Combined PDF: 'T2_ALL_OUTPUTS_MERGED_YYYYMMDD_HHMM.pdf'
  - Contents: All discovered PDFs merged in deterministic order
  - Bookmarks: One top-level bookmark per source file (when using PyPDF2/pypdf; pikepdf fallback may omit bookmarks)
  - Page header: Each page is stamped at the top with the name of the program that produced that PDF (best-effort)
- Audit Log Excel: 'T2_ALL_OUTPUTS_MERGED_LOG_YYYYMMDD_HHMM.xlsx'
  - Columns: absolute_path, file_name, directory, step_major, step_minor, start_page_1_based, page_count, timestamp_merged
  - Cell A1 comment: 'Generated by: <full path to this script>'
  - Date formatting applied to timestamp_merged; column width set for readability

Version History:
- 1.0.0 (2025-08-08): Initial release - discovery, deterministic ordering, PDF merge, bookmarks (PyPDF2/pypdf), Excel audit log with date formatting

Usage (CLI):
  python "Step Twenty One Master Report.py" \
    [--root "/path/to/specific/directory"] \
    [--include-substr Step] [--exclude-substr docs] [--dry-run] [--no-bookmarks] \
    [--output-pdf "/path/to/output.pdf"] [--log-xlsx "/path/to/log.xlsx"] [--verbose]

Notes:
- By default, scans the current script directory for PDFs
- Use --root to specify a different directory if needed
- This script does not modify, move, or delete any source PDF files.
- Bookmarks require 'PyPDF2' or 'pypdf'. If neither is available, the script will attempt to merge using 'pikepdf' without bookmarks.
- If no compatible PDF library is installed, the script will exit with instructions to install one.
"""

from __future__ import annotations

import argparse
import datetime as dt
import os
import re
import sys
from dataclasses import dataclass
from io import BytesIO
import tempfile
from pathlib import Path
from typing import Callable, Iterable, List, Optional, Sequence, Tuple

import pandas as pd


__version__ = "1.2.0"
LAST_UPDATED = "2025-08-08"


# -----------------------------
# Data Structures
# -----------------------------

@dataclass
class PdfEntry:
    absolute_path: Path
    file_name: str
    directory: Path
    step_major: int
    step_minor: int
    page_count: Optional[int]
    start_page_1_based: Optional[int]
    producer_script: Optional[str] = None


# -----------------------------
# Step Parsing Utilities
# -----------------------------

_WORD_TO_INT = {
    "zero": 0,
    "one": 1,
    "two": 2,
    "three": 3,
    "four": 4,
    "five": 5,
    "six": 6,
    "seven": 7,
    "eight": 8,
    "nine": 9,
    "ten": 10,
    "eleven": 11,
    "twelve": 12,
    "thirteen": 13,
    "fourteen": 14,
    "fifteen": 15,
    "sixteen": 16,
    "seventeen": 17,
    "eighteen": 18,
    "nineteen": 19,
    "twenty": 20,
    "thirty": 30,
    "forty": 40,
    "fifty": 50,
}


def _word_number_to_int(words: Sequence[str]) -> Optional[int]:
    """Convert word-number sequences like ['twenty', 'one'] -> 21; ['six'] -> 6.

    Returns None if unrecognized.
    """
    if not words:
        return None
    words = [w.lower() for w in words if w]
    if len(words) == 1:
        return _WORD_TO_INT.get(words[0])
    if len(words) >= 2:
        first = _WORD_TO_INT.get(words[0])
        second = _WORD_TO_INT.get(words[1])
        if first is not None and second is not None and first in {20, 30, 40, 50} and 0 < second < 10:
            return first + second
        if first is not None and words[1] == "point" and len(words) >= 3:
            # major only; minor handled separately by caller
            return first
    return None


def parse_step_order_from_path(path: Path) -> Tuple[int, int]:
    """Extract (major, minor) step order from a filename or its parent directories.

    Supported patterns (case-insensitive):
    - 'Step 5', 'Step Five'
    - 'Step Five Point Two' -> (5, 2)
    - 'Step Twenty One' -> (21, 0)
    Falls back to (9999, 0) if not found.
    """
    text = str(path).lower()

    # 1) Numeric with optional 'Point' minor, e.g., Step 5 Point 2
    m = re.search(r"step\s+(\d+)(?:\s+point\s+(\d+))?", text)
    if m:
        major = int(m.group(1))
        minor = int(m.group(2)) if m.group(2) else 0
        return major, minor

    # 2) Word number with optional 'Point' word number, e.g., Step Five Point Two
    m = re.search(r"step\s+([a-z]+)(?:\s+point\s+([a-z]+))?", text)
    if m:
        major_word = m.group(1)
        minor_word = m.group(2)
        major = _WORD_TO_INT.get(major_word)
        minor = _WORD_TO_INT.get(minor_word) if minor_word else 0
        if major is not None:
            return major, minor

    # 3) Two-word major like 'Step Twenty One'
    m = re.search(r"step\s+([a-z]+)\s+([a-z]+)", text)
    if m:
        major = _word_number_to_int([m.group(1), m.group(2)])
        if major is not None:
            return major, 0

    # 4) Single-word major like 'Step Six'
    m = re.search(r"step\s+([a-z]+)", text)
    if m:
        major = _word_number_to_int([m.group(1)])
        if major is not None:
            return major, 0

    return 9999, 0


# -----------------------------
# PDF Library Adapter
# -----------------------------

class PdfMergeAdapter:
    """Abstracts over different PDF backends (pypdf/PyPDF2 or pikepdf)."""

    def __init__(self) -> None:
        self.backend: str = ""
        self._merger = None
        self._reader_cls = None

        # Try pypdf first (modern), then PyPDF2, then pikepdf
        try:
            import pypdf as _pypdf  # type: ignore

            self.backend = "pypdf"
            self._merger = _pypdf.PdfMerger()
            self._reader_cls = _pypdf.PdfReader
            return
        except Exception:
            pass

        try:
            import PyPDF2 as _pypdf  # type: ignore

            self.backend = "PyPDF2"
            self._merger = _pypdf.PdfMerger()
            self._reader_cls = _pypdf.PdfReader
            return
        except Exception:
            pass

        try:
            import pikepdf as _pike  # type: ignore

            self.backend = "pikepdf"
            self._pike = _pike
            self._dest_pdf = _pike.Pdf.new()
            self._outline_root = None  # pikepdf outline support is optional here
            return
        except Exception:
            pass

        raise RuntimeError(
            "No compatible PDF library found. Please install one of: 'pypdf' (preferred), 'PyPDF2', or 'pikepdf'.\n"
            "Try: pip install pypdf || pip install PyPDF2 || pip install pikepdf"
        )

    def count_pages(self, file_path: Path) -> Optional[int]:
        try:
            if self.backend in {"pypdf", "PyPDF2"}:
                reader = self._reader_cls(str(file_path))
                try:
                    return len(reader.pages)
                except Exception:
                    # Older API compatibility
                    return reader.getNumPages()  # type: ignore[attr-defined]
            elif self.backend == "pikepdf":
                pdf = self._pike.Pdf.open(str(file_path))
                try:
                    return len(pdf.pages)
                finally:
                    pdf.close()
        except Exception:
            return None
        return None

    def _create_header_overlay(self, width_pts: float, height_pts: float, text: str) -> Optional[BytesIO]:
        if not text:
            return None
        try:
            # Create a single-page PDF overlay with ReportLab
            from reportlab.lib.pagesizes import portrait
            from reportlab.pdfgen import canvas
            from reportlab.lib.colors import Color

            buf = BytesIO()
            c = canvas.Canvas(buf, pagesize=(width_pts, height_pts))
            font_size = 11
            c.setFont("Helvetica", font_size)
            # Dark gray for visibility
            c.setFillColor(Color(0.15, 0.15, 0.15))
            margin = 16

            # Truncate header if wider than page
            header = text or ""
            max_width = max(10.0, width_pts - 2 * margin)
            while c.stringWidth(header, "Helvetica", font_size) > max_width and len(header) > 3:
                header = header[:-4] + "â€¦"

            # Top-left placement
            x = margin
            y = height_pts - margin
            c.drawString(x, y, header)

            # Light divider line under header
            c.setStrokeColor(Color(0.7, 0.7, 0.7))
            c.setLineWidth(0.5)
            c.line(margin, y - 4, width_pts - margin, y - 4)
            c.save()
            buf.seek(0)
            return buf
        except Exception:
            return None

    def append(self, file_path: Path, header_text: str = "") -> None:
        if self.backend in {"pypdf", "PyPDF2"}:
            # If a header is requested, stamp each page before appending
            if header_text:
                try:
                    # Re-import backend to access PdfWriter
                    if self.backend == "pypdf":
                        import pypdf as _pypdf  # type: ignore
                    else:
                        import PyPDF2 as _pypdf  # type: ignore

                    reader = self._reader_cls(str(file_path))
                    writer = _pypdf.PdfWriter()
                    for page in reader.pages:
                        try:
                            width = float(page.mediabox.width)
                            height = float(page.mediabox.height)
                        except Exception:
                            # Fallback to default letter size if unknown
                            width, height = 612.0, 792.0
                        overlay_buf = self._create_header_overlay(width, height, header_text)
                        if overlay_buf is not None:
                            overlay_reader = _pypdf.PdfReader(overlay_buf)
                            overlay_page = overlay_reader.pages[0]
                            try:
                                # pypdf >=3
                                page.merge_page(overlay_page)
                            except Exception:
                                # PyPDF2 older
                                page.mergePage(overlay_page)
                        writer.add_page(page)

                    # Write to a temporary stamped file, then append
                    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                        writer.write(tmp)
                        tmp_path = tmp.name
                    self._merger.append(tmp_path)
                    return
                except Exception:
                    # Fallback: append original if stamping fails
                    self._merger.append(str(file_path))
                    return

            # No header requested
            self._merger.append(str(file_path))
        elif self.backend == "pikepdf":
            src = self._pike.Pdf.open(str(file_path))
            try:
                self._dest_pdf.pages.extend(src.pages)
            finally:
                src.close()

    def add_bookmark(self, title: str, page_index_zero_based: int) -> None:
        if self.backend in {"pypdf", "PyPDF2"}:
            try:
                # pypdf >=3
                self._merger.add_outline_item(title, page_index_zero_based)
                return
            except Exception:
                pass
            try:
                # PyPDF2 <=2
                self._merger.addBookmark(title, page_index_zero_based)
                return
            except Exception:
                pass
        elif self.backend == "pikepdf":
            # Simple fallback: skip bookmarks to avoid fragile outline APIs across versions
            return

    def set_metadata(self, title: str, author: str, creator: str) -> None:
        if self.backend in {"pypdf", "PyPDF2"}:
            try:
                self._merger.add_metadata({
                    "/Title": title,
                    "/Author": author,
                    "/Creator": creator,
                })
            except Exception:
                try:
                    self._merger.addMetadata({
                        "/Title": title,
                        "/Author": author,
                        "/Creator": creator,
                    })
                except Exception:
                    pass
        elif self.backend == "pikepdf":
            try:
                self._dest_pdf.docinfo.update({
                    self._pike.Name("Title"): title,
                    self._pike.Name("Author"): author,
                    self._pike.Name("Creator"): creator,
                })
            except Exception:
                pass

    def write(self, output_path: Path) -> None:
        if self.backend in {"pypdf", "PyPDF2"}:
            with open(output_path, "wb") as f_out:
                self._merger.write(f_out)
            try:
                self._merger.close()
            except Exception:
                pass
        elif self.backend == "pikepdf":
            self._dest_pdf.save(str(output_path))
            try:
                self._dest_pdf.close()
            except Exception:
                pass


# -----------------------------
# Discovery and Ordering
# -----------------------------

def discover_pdfs(
    root: Path,
    include_substr: Optional[Sequence[str]] = None,
    exclude_substr: Optional[Sequence[str]] = None,
) -> List[Path]:
    include_substr = [s.lower() for s in (include_substr or [])]
    exclude_substr = [s.lower() for s in (exclude_substr or [])]

    pdfs: List[Path] = []
    for p in root.rglob("*.pdf"):
        path_l = str(p).lower()
        if include_substr and not any(s in path_l for s in include_substr):
            continue
        if exclude_substr and any(s in path_l for s in exclude_substr):
            continue
        pdfs.append(p)
    return pdfs


def _scan_step_scripts_for_pdf_mapping(root: Path) -> Tuple[dict, List[Tuple[str, Tuple[int, int]]]]:
    """Scan step scripts in the root directory for PDF outputs and map them to step order.

    Returns:
        exact_map: {base_pdf_name: (major, minor, script_name)}
        prefix_list: [(base_prefix, (major, minor, script_name))] for dynamic f-strings like 'name_{date}.pdf'
                      The list is sorted by decreasing prefix length to prefer the most specific match.
    """
    exact_map: dict[str, Tuple[int, int, str]] = {}
    prefix_list: List[Tuple[str, Tuple[int, int, str]]] = []

    pdf_literal_pattern = re.compile(r"(['\"])((?:[^'\"\\]|\\.)*?\.pdf)\1", re.IGNORECASE)

    for script_path in root.glob("*.py"):
        # Skip self
        if script_path.name.lower() == "step twenty one master report.py".lower():
            continue

        # Only consider files that look like step scripts
        step_major, step_minor = parse_step_order_from_path(script_path)
        if step_major == 9999:
            continue

        try:
            text = script_path.read_text(encoding="utf-8", errors="ignore")
        except Exception:
            continue

        for m in pdf_literal_pattern.finditer(text):
            raw = m.group(2)
            # Ignore obvious non-file settings like format='pdf' (no '.pdf') â€“ already filtered
            # Convert to base name
            if "{" in raw and "}" in raw:
                # Dynamic f-string -> use prefix up to first '{'
                prefix = raw.split("{", 1)[0]
                base_prefix = os.path.basename(prefix)
                if not base_prefix:
                    continue
                prefix_list.append((base_prefix, (step_major, step_minor, script_path.name)))
            else:
                base_name = os.path.basename(raw)
                if not base_name:
                    continue
                # Prefer the lowest step (earliest in the pipeline) if duplicates appear
                existing = exact_map.get(base_name)
                if existing is None or (step_major, step_minor) < (existing[0], existing[1]):
                    exact_map[base_name] = (step_major, step_minor, script_path.name)

    # Sort prefixes by decreasing length for best-match behavior
    prefix_list.sort(key=lambda t: len(t[0]), reverse=True)
    return exact_map, prefix_list


def _resolve_step_for_pdf_name(
    base_name: str,
    exact_map: dict,
    prefix_list: List[Tuple[str, Tuple[int, int, str]]],
) -> Optional[Tuple[int, int, str]]:
    if base_name in exact_map:
        return exact_map[base_name]
    for prefix, step in prefix_list:
        if base_name.startswith(prefix):
            return step
    return None


def build_sorted_entries(paths: Sequence[Path], root: Path) -> List[PdfEntry]:
    # Build mapping from step scripts -> their produced PDF names (exact and dynamic prefixes)
    exact_map, prefix_list = _scan_step_scripts_for_pdf_mapping(root)

    entries: List[PdfEntry] = []
    for p in paths:
        # Determine step by scanning script mappings first (semantic order), then fallback to PDF path parsing
        base_name = p.name
        step_info = _resolve_step_for_pdf_name(base_name, exact_map, prefix_list)
        if step_info is not None:
            major, minor, script_name = step_info
        else:
            major, minor = parse_step_order_from_path(p)
            script_name = None
        entries.append(
            PdfEntry(
                absolute_path=p.resolve(),
                file_name=p.name,
                directory=p.resolve().parent,
                step_major=major,
                step_minor=minor,
                page_count=None,
                start_page_1_based=None,
                producer_script=script_name,
            )
        )

    entries.sort(
        key=lambda e: (
            e.step_major,
            e.step_minor,
            e.file_name.lower(),
            str(e.absolute_path).lower(),
        )
    )
    return entries


# -----------------------------
# Merge and Logging
# -----------------------------

def merge_pdfs_with_log(
    entries: List[PdfEntry],
    output_pdf: Path,
    write_bookmarks: bool,
    verbose: bool,
) -> List[PdfEntry]:
    adapter = PdfMergeAdapter()
    if verbose:
        print(f"Using PDF backend: {adapter.backend}")

    # Count pages and compute starting page indices
    current_start = 1
    for e in entries:
        e.page_count = adapter.count_pages(e.absolute_path)
        e.start_page_1_based = current_start
        if e.page_count is None:
            if verbose:
                print(f"Warning: Unable to read page count for: {e.absolute_path}")
            # Still attempt to append; will increment start by 0
            pass
        else:
            current_start += e.page_count

    # Append and add bookmarks
    for e in entries:
        try:
            header_text = e.producer_script or ""
            adapter.append(e.absolute_path, header_text=header_text)
            if write_bookmarks and e.start_page_1_based is not None and e.page_count is not None:
                adapter.add_bookmark(e.file_name, e.start_page_1_based - 1)
        except Exception as ex:
            print(f"Error appending {e.absolute_path}: {ex}")

    script_path = os.path.abspath(sys.argv[0])
    adapter.set_metadata(
        title=f"Merged Outputs {dt.datetime.now():%Y-%m-%d %H:%M}",
        author="T2 Factor Timing System",
        creator=script_path,
    )
    adapter.write(output_pdf)
    if verbose:
        print(f"Wrote merged PDF: {output_pdf}")

    return entries


def write_excel_log(entries: List[PdfEntry], log_xlsx: Path, verbose: bool) -> None:
    script_path = os.path.abspath(sys.argv[0])
    timestamp = dt.datetime.now()

    rows = []
    for e in entries:
        rows.append(
            {
                "absolute_path": str(e.absolute_path),
                "file_name": e.file_name,
                "directory": str(e.directory),
                "step_major": e.step_major,
                "step_minor": e.step_minor,
                "start_page_1_based": e.start_page_1_based,
                "page_count": e.page_count,
                "timestamp_merged": timestamp,
            }
        )

    df = pd.DataFrame(rows)

    with pd.ExcelWriter(log_xlsx, engine="xlsxwriter") as writer:
        df.to_excel(writer, sheet_name="Log", index=False)
        workbook = writer.book
        worksheet = writer.sheets["Log"]

        # Add program path as a comment in A1 per workspace rules
        worksheet.write_comment("A1", f"Generated by: {script_path}")

        # Apply date format to timestamp_merged per workspace rules
        date_format = workbook.add_format({"num_format": "dd-mmm-yyyy hh:mm:ss"})
        if "timestamp_merged" in df.columns:
            col_idx = df.columns.get_loc("timestamp_merged")
            # Set a comfortable width
            worksheet.set_column(col_idx, col_idx, 22)
            for row in range(len(df)):
                worksheet.write(row + 1, col_idx, df["timestamp_merged"].iloc[row], date_format)

        # Optional: make path columns wider for readability
        if "absolute_path" in df.columns:
            col_idx = df.columns.get_loc("absolute_path")
            worksheet.set_column(col_idx, col_idx, 100)
        if "file_name" in df.columns:
            col_idx = df.columns.get_loc("file_name")
            worksheet.set_column(col_idx, col_idx, 40)
        if "directory" in df.columns:
            col_idx = df.columns.get_loc("directory")
            worksheet.set_column(col_idx, col_idx, 80)

    if verbose:
        print(f"Wrote Excel log: {log_xlsx}")


# -----------------------------
# CLI
# -----------------------------

def build_arg_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(
        description=(
            "Discover all PDFs under a root directory, merge them into a single PDF in deterministic order, "
            "and write an Excel audit log with proper date formatting."
        )
    )
    parser.add_argument(
        "--root",
        type=str,
        default=str(Path(__file__).resolve().parent),
        help="Root directory to scan for PDFs (default: script directory)",
    )
    parser.add_argument(
        "--include-substr",
        type=str,
        nargs="*",
        default=None,
        help=(
            "Only include PDFs whose full path contains any of these substrings (case-insensitive). "
            "Example: --include-substr Step"
        ),
    )
    parser.add_argument(
        "--exclude-substr",
        type=str,
        nargs="*",
        default=None,
        help=(
            "Exclude PDFs whose full path contains any of these substrings (case-insensitive). "
            "Example: --exclude-substr docs Archive"
        ),
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="List discovered PDFs and their order, but do not merge or write logs.",
    )
    parser.add_argument(
        "--no-bookmarks",
        action="store_true",
        help="Disable adding bookmarks to the merged PDF (PyPDF2/pypdf only).",
    )
    parser.add_argument(
        "--output-pdf",
        type=str,
        default=None,
        help="Output PDF file path. Default is T2_ALL_OUTPUTS_MERGED_YYYYMMDD_HHMM.pdf in --root.",
    )
    parser.add_argument(
        "--log-xlsx",
        type=str,
        default=None,
        help="Output Excel log file path. Default is T2_ALL_OUTPUTS_MERGED_LOG_YYYYMMDD_HHMM.xlsx in --root.",
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Verbose console output",
    )
    return parser


def main(argv: Optional[Sequence[str]] = None) -> int:
    parser = build_arg_parser()
    args = parser.parse_args(argv)

    root = Path(args.root).expanduser().resolve()
    if not root.exists() or not root.is_dir():
        print(f"Root path does not exist or is not a directory: {root}")
        return 1

    ts = dt.datetime.now()
    default_pdf = root / f"T2_ALL_OUTPUTS_MERGED_{ts:%Y%m%d_%H%M}.pdf"
    default_log = root / f"T2_ALL_OUTPUTS_MERGED_LOG_{ts:%Y%m%d_%H%M}.xlsx"
    output_pdf = Path(args.output_pdf).expanduser().resolve() if args.output_pdf else default_pdf
    log_xlsx = Path(args.log_xlsx).expanduser().resolve() if args.log_xlsx else default_log

    if args.verbose:
        print(f"Scanning root: {root}")
    pdf_paths = discover_pdfs(root, args.include_substr, args.exclude_substr)
    if not pdf_paths:
        print("No PDF files found under the root with the given filters.")
        return 2

    entries = build_sorted_entries(pdf_paths, root=root)

    # Dry run: show manifest
    if args.dry_run:
        print("Planned merge order (major.minor :: file):")
        for e in entries:
            print(f"  {e.step_major}.{e.step_minor:02d} :: {e.absolute_path}")
        return 0

    try:
        entries = merge_pdfs_with_log(
            entries=entries,
            output_pdf=output_pdf,
            write_bookmarks=(not args.no_bookmarks),
            verbose=args.verbose,
        )
    except RuntimeError as ex:
        print(str(ex))
        return 3

    try:
        write_excel_log(entries, log_xlsx=log_xlsx, verbose=args.verbose)
    except Exception as ex:
        print(f"Failed to write Excel log: {ex}")
        return 4

    if args.verbose:
        total_pages = sum(e.page_count or 0 for e in entries)
        print(f"Done. Files merged: {len(entries)} | Total pages: {total_pages}")
        print(f"Output PDF: {output_pdf}")
        print(f"Audit Log : {log_xlsx}")

    return 0


if __name__ == "__main__":
    sys.exit(main())


